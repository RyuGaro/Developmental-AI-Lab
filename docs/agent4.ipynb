{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74eb8609-bd0c-4a26-94be-5cf56d9f58cb",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/OlivierGeorgeon/Developmental-AI-Lab/blob/master/docs/agent4.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec58b3-e210-4a78-9610-f6615254de29",
   "metadata": {},
   "source": [
    "# THE AGENT WHO SHIFTED WITH THE CONTEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ef995-42ce-44ba-9f3b-8bfa808b08fe",
   "metadata": {},
   "source": [
    "# Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de14a47d-ca87-4080-8f84-afcd2bc83170",
   "metadata": {},
   "source": [
    "Upon completing this lab, you will be able to implement a developmental agent driven by interactional motivation that adapts its next action based on the context of the previously enacted interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a16db8-1bd6-4e82-9cf6-2b37d996ffe8",
   "metadata": {},
   "source": [
    "## Define the Interaction class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44155c4a-d038-40b3-be33-e8cf77c5f976",
   "metadata": {},
   "source": [
    "Let's define an Interaction class that will be useful to intitialize the agent and to memorize the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e96c3637-4161-49aa-9f1d-0d3342de92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interaction:\n",
    "    \"\"\"An interaction is a tuple (action, outcome) with a valence\"\"\"\n",
    "    def __init__(self, action, outcome, valence):\n",
    "        self.action = action\n",
    "        self.outcome = outcome\n",
    "        self.valence = valence\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictinary is the string '<action><outcome>'. \"\"\"\n",
    "        return f\"{self.action}{self.outcome}\"\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print interaction in the form '<action><outcome:<valence>' for debug.\"\"\"\n",
    "        return f\"{self.action}{self.outcome}:{self.valence}\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same key \"\"\"\n",
    "        return self.key() == other.key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152512a3-ef97-473a-91a7-9a36fe70ba33",
   "metadata": {},
   "source": [
    "## Define the Agent class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b81c3-5671-4ec6-bb7d-9db4f99c7c0b",
   "metadata": {},
   "source": [
    "The agent is initialized with the list of interactions \n",
    "\n",
    "The previous action and the predicted outcome are memorized in the attribute `_intended_interaction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3f0bf369-48ef-48d7-a92b-3c7ef8dc1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"Creating our agent\"\"\"\n",
    "    def __init__(self, _interactions):\n",
    "        \"\"\" Initialize the dictionary of interactions\"\"\"\n",
    "        self._interactions = {interaction.key(): interaction for interaction in _interactions}\n",
    "        self._intended_interaction = self._interactions[\"00\"]\n",
    "\n",
    "    def action(self, _outcome):\n",
    "        \"\"\" Tracing the previous cycle \"\"\"\n",
    "        previous_interaction = self._interactions[f\"{self._intended_interaction.action}{_outcome}\"]\n",
    "        print(f\"Action: {self._intended_interaction.action}, Prediction: {self._intended_interaction.outcome}, Outcome: {_outcome}, \" \n",
    "              f\"Prediction: {self._intended_interaction.outcome == _outcome}, Valence: {previous_interaction.valence})\")\n",
    "\n",
    "        \"\"\" Computing the next interaction to try to enact \"\"\"\n",
    "        # TODO: Implement the agent's decision mechanism\n",
    "        intended_action = 0\n",
    "        # TODO: Implement the agent's prediction mechanism\n",
    "        intended_outcome = 0\n",
    "        # Memorize the intended interaction\n",
    "        self._intended_interaction = self._interactions[f\"{intended_action}{intended_outcome}\"]\n",
    "        return intended_action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1c38f-c8ed-48e5-bc6a-e7078ed3e5e4",
   "metadata": {},
   "source": [
    "## Environment1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8d65ca61-9386-4260-a406-ec766063569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment1:\n",
    "    \"\"\" In Environment 1, action 0 yields outcome 0, action 1 yields outcome 1 \"\"\"\n",
    "    def outcome(self, _action):\n",
    "        # return int(input(\"entre 0 1 ou 2\"))\n",
    "        if _action == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6d7d6-5444-4778-b97a-cc5bd34c6cd2",
   "metadata": {},
   "source": [
    "## Environment2 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "91ae8fba-72aa-4194-be5a-2f27a1637e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment2:\n",
    "    \"\"\" In Environment 2, action 0 yields outcome 1, action 1 yields outcome 0 \"\"\"\n",
    "    def outcome(self, _action):\n",
    "        if _action == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dab7280-a559-4fc2-8668-4285aac82d8d",
   "metadata": {},
   "source": [
    "## Environment3 class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df2375-680e-4df9-a0ed-e84802aac1a4",
   "metadata": {},
   "source": [
    "Environment 3 yields outcome 1 only when the agent alternates actions 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5bf9a4ba-2703-49e9-a63f-b72c08b8663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment3:\n",
    "    \"\"\" Environment 3 yields outcome 1 only when the agent alternates actions 0 and 1 \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializing Environment3 \"\"\"\n",
    "        self.previous_action = 0\n",
    "\n",
    "    def outcome(self, _action):\n",
    "        if _action == self.previous_action:\n",
    "            _outcome = 0\n",
    "        else:\n",
    "            _outcome = 1\n",
    "        self.previous_action = _action\n",
    "        return _outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2f49f7-9352-4938-9ee2-7d8a7bb5065a",
   "metadata": {},
   "source": [
    "## Initialize the interactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "59da5f51-d5db-4cf4-8bd0-036ec11eaad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = [\n",
    "    Interaction(0,0,-1),\n",
    "    Interaction(0,1,1),\n",
    "    Interaction(1,0,-1),\n",
    "    Interaction(1,1,1),\n",
    "    Interaction(2,0,-1),\n",
    "    Interaction(2,1,1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d25cea-a183-45c5-a624-1345aace245a",
   "metadata": {},
   "source": [
    "Interactions are initialized with their action, their outcome, and their valence:\n",
    "\n",
    "|| outcome 0 | outcome 1|\n",
    "|---|---|---|\n",
    "| action 0| -1 | 1 |\n",
    "| action 1 | -1 | 1 |\n",
    "| action 2 | -1 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f095ec84-3fcd-455c-bb3b-f9a72980048e",
   "metadata": {},
   "source": [
    "## Instantiate the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "33066d34-7f06-4b38-97b8-d7d5adbb237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Agent(interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16279c4-936b-4f37-a0c9-ca4b77609adf",
   "metadata": {},
   "source": [
    "## Instantiate the environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "17b3c8c8-0cbd-4f64-a97c-61519ad24dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Environment3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ce510-9438-47d1-ac88-ab79c063d592",
   "metadata": {},
   "source": [
    "## Test run the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6d76df-89e4-4ab3-a327-afa813a27325",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 0\n",
    "for i in range(10):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febad285-e8e5-4c24-a46e-e9519a27581c",
   "metadata": {},
   "source": [
    "Observe that in Envirnment3, the agent obtains only negative valences. To obtain a positive valence, it must select a different action on each interaction cycle. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3019f138-a218-44b2-964a-8095fbe891a7",
   "metadata": {},
   "source": [
    "# PRELIMINARY EXERCISE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9daa278-434e-43ce-8520-8fabef69cd83",
   "metadata": {},
   "source": [
    "Execute the agent in Environment1. Observe that it obtains a negative valence. \n",
    "\n",
    "Execute the agent in Environment2. Observe that it obtains a positive valence. \n",
    "\n",
    "Now you see the goal of this assignement: design an agent that can obtain positive valences when it is run either in Environment1 or in Environment2 or in Environment3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d50d96e-4f12-4531-a122-9d13d8bd8639",
   "metadata": {},
   "source": [
    "# ASSIGNMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199faee9-a546-4d86-8e09-484bf2212523",
   "metadata": {},
   "source": [
    "Implement Agent4 that obtains positive valences in either Environment 1, 2, or 3. \n",
    "\n",
    "Agent4 must be able to predict the outcome resulting from its next action depending on the context of the previous interaction. \n",
    "Based on this prediction, it must select the action that will yield the heighest valence. \n",
    "\n",
    "To do so, at the end of cycle `t`, Agent4 must memorize `interaction_t = (action_t, outcome_t)` that was just enacted. \n",
    "The agent must choose the next `interaction_t+1` based on `interaction_t` (the context).\n",
    "For each possible `action_t+1`, the agent must predict the expected `outcome_t+1`. \n",
    "Based on this prediction, it must select the action that yields the highest `valence_t+1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82b9a28-121c-4379-8701-1d49ad197b8d",
   "metadata": {},
   "source": [
    "## Create Agent4 by overriding the class Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b9ba2b-8129-4bf7-82dc-074803f95bdf",
   "metadata": {},
   "source": [
    "You may add any attribute and method you deem usefull to the class Agent4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "85b966d4-aca5-4a08-8413-d4906fdbbae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent4(Agent):\n",
    "    pass\n",
    "    # TODO override the method action(self, _outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b3f5c-f48c-45ad-bf1d-4a703bac64af",
   "metadata": {},
   "source": [
    "## Test your Agent4 in Environment1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8025780-7d39-442d-9600-b40641e6d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Agent4(interactions)\n",
    "e = Environment1()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce02f401-3a78-4ced-9b8c-3b602c7be482",
   "metadata": {},
   "source": [
    "## Test your Agent4 in Environment2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925fb5f1-1eb6-4dee-a59b-fd6384e123d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Agent4(interactions)\n",
    "e = Environment2()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4ebe13-605e-4068-ab57-06416f898790",
   "metadata": {},
   "source": [
    "## Test your Agent4 in Environment3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835595f7-512e-46aa-b140-3e2b6c43eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Agent4(interactions)\n",
    "e = Environment3()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afc8226-b4ac-49c7-b1a8-9b17adc19964",
   "metadata": {},
   "source": [
    "## Test your Agent4 with interactions that have other valences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01175431-ead3-480e-b8e3-e20ee9321379",
   "metadata": {},
   "source": [
    "Replace the valences of interactions with your choice in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fdfd38-0d4e-48a3-ab0f-87177c2da97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose different valence of interactions\n",
    "interactions = [\n",
    "    Interaction(0,0,1),\n",
    "    Interaction(0,1,0),\n",
    "    Interaction(1,0,-1),\n",
    "    Interaction(1,1,1),\n",
    "    Interaction(2,0,-1),\n",
    "    Interaction(2,1,1)\n",
    "]\n",
    "# Run the agent\n",
    "a = Agent4(interactions)\n",
    "e = Environment3()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a1c321-c33f-497e-8219-a0904ab6ebab",
   "metadata": {},
   "source": [
    "## Test your agent in the Turtle environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71630824-e023-49b7-a143-6ffccae07209",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# @title Install the turtle environment\n",
    "!pip3 install ColabTurtle\n",
    "from ColabTurtle.Turtle import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f35913a4-4426-4e50-ba74-6790e579fb80",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# @title Initialize the turtle environment\n",
    "\n",
    "BORDER_WIDTH = 20\n",
    "\n",
    "class ColabTurtleEnvironment:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Creating the Turtle window \"\"\"\n",
    "        bgcolor(\"lightGray\")\n",
    "        penup()\n",
    "        goto(window_width() / 2, window_height()/2)\n",
    "        face(0)\n",
    "        pendown()\n",
    "        color(\"green\")\n",
    "\n",
    "    def outcome(self, action):\n",
    "        \"\"\" Enacting an action and returning the outcome \"\"\"\n",
    "        _outcome = 0\n",
    "        for i in range(10):\n",
    "            # _outcome = 0\n",
    "            if action == 0:\n",
    "                # move forward\n",
    "                forward(10)\n",
    "            elif action == 1:\n",
    "                # rotate left\n",
    "                left(4)\n",
    "                forward(2)\n",
    "            elif action == 2:\n",
    "                # rotate right\n",
    "                right(4)\n",
    "                forward(2)\n",
    "\n",
    "            # Bump on screen edge and return outcome 1\n",
    "            if xcor() < BORDER_WIDTH:\n",
    "                goto(BORDER_WIDTH, ycor())\n",
    "                _outcome = 1\n",
    "            if xcor() > window_width() - BORDER_WIDTH:\n",
    "                goto(window_width() - BORDER_WIDTH, ycor())\n",
    "                _outcome = 1\n",
    "            if ycor() < BORDER_WIDTH:\n",
    "                goto(xcor(), BORDER_WIDTH)\n",
    "                _outcome = 1\n",
    "            if ycor() > window_height() - BORDER_WIDTH:\n",
    "                goto(xcor(), window_height() -BORDER_WIDTH)\n",
    "                _outcome = 1\n",
    "\n",
    "            # Change color\n",
    "            if _outcome == 0:\n",
    "                color(\"green\")\n",
    "            else:\n",
    "                # Finit l'interaction\n",
    "                color(\"red\")\n",
    "                # if action == 0:\n",
    "                #     break\n",
    "                if action == 1:\n",
    "                    for j in range(10):\n",
    "                        left(4)\n",
    "                elif action == 2:\n",
    "                    for j in range(10):\n",
    "                        right(4)\n",
    "                break\n",
    "\n",
    "        return _outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb4b183-a761-47c8-a3a5-957467dd5675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Run the turtle environment\n",
    "initializeTurtle()\n",
    "\n",
    "# Parameterize the rendering\n",
    "bgcolor(\"lightGray\")\n",
    "penup()\n",
    "goto(window_width() / 2, window_height()/2)\n",
    "face(0)\n",
    "pendown()\n",
    "color(\"green\")\n",
    "speed(10)\n",
    "\n",
    "a = Agent4(interactions)\n",
    "e = ColabTurtleEnvironment()\n",
    "\n",
    "outcome = 0\n",
    "for i in range(10):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac15a134-34a6-4039-9b43-f8fd76d93b5e",
   "metadata": {},
   "source": [
    "## Report "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e661c15-c1ed-4512-a1d9-0fbdb8f91879",
   "metadata": {},
   "source": [
    "Explain what you programmed and what results you observed. Export this document as PDF including your code, the traces you obtained, and your explanations below (no more than a few paragraphs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc0899-eee2-404a-baf6-47741067e7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
